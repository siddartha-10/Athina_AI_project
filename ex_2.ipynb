{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI, ChatOpenAI\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer # type: ignore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "# from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import InMemoryCache\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "import tqdm\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    temperature = 0.4,\n",
    "    max_tokens = 400,\n",
    ")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"policy_data.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=700,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_text = [pages.page_content for pages in pages]\n",
    "# the type of pages is documents but we need to convert them into list of strings for splitting the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = splitter.create_documents(pages_text)\n",
    "# splitting the text into chunks of 250 characters and 50 characters overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='About the policy\\nThe policy is made up of:\\n >This booklet.\\n >Your car insurance details.\\n >Your certificate (or certificates)  \\nof motor insurance.\\nIf the policy includes Green Flag breakdown cover:\\n >Your breakdown cover and your car \\ninsurance are part of the same policy.\\n >The policy also includes the Green Flag \\npolicy booklet we’ve given you.\\nIf you have a policy that includes DriveSure:\\n >The policy also includes the DriveSure terms \\nand conditions we’ve given you.\\nPlease read all these documents carefully  and keep them safe in case you need them.Words in bold type\\nSome of the words and phrases we use in \\nthis booklet have a specific meaning – for example, your car or modifications.'\n"
     ]
    }
   ],
   "source": [
    "print(documents[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorstore(text_chunks):\n",
    "    # Check if the FAISS index file already exists\n",
    "    if os.path.exists(\"faiss_index\"):\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        # Load the existing FAISS index\n",
    "        vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True) # used this because it is my local desktop mode\n",
    "        print(\"Loaded existing FAISS index.\")\n",
    "    else:\n",
    "        # Create a new FAISS index\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        vectorstore = FAISS.from_documents(documents=text_chunks, embedding=embeddings)\n",
    "        # Save the new FAISS index locally\n",
    "        vectorstore.save_local(\"faiss_index\")\n",
    "        print(\"Created and saved new FAISS index.\")\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing FAISS index.\n"
     ]
    }
   ],
   "source": [
    "vectorstore = get_vectorstore(documents).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the context below to answer the question.\n",
    "Keep the answer concise and to the point.\n",
    "If you are unsure about the answer, just say i do not know the answer to the question do not create your own answer and make sure the answer is concise and to the point.\n",
    "Summarize the information such that main points are covered and if you think that there needs to be some more information added to the answer then you can add that information as well.\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('/Users/siddartha/Desktop/github/Athina_AI_project/dataset_testing/dataset_for_testing.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[\"question\"].to_list()\n",
    "ground_truth = df[\"ground_truth\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "data = {\"question\": [], \"response\": [], \"contexts\": [], \"ground_truth\": ground_truth}\n",
    "\n",
    "for query in questions:\n",
    "    data[\"question\"].append(query)\n",
    "    data[\"response\"].append(chain.invoke(query))\n",
    "    data[\"contexts\"].append([doc.page_content for doc in vectorstore.get_relevant_documents(query, top_k=5)])\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response'] = df['response'].apply(lambda x: x['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_dataset_testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
